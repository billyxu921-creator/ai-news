import arxiv
import google.generativeai as genai
import json
from datetime import datetime

# 1. é…ç½® Gemini
genai.configure(api_key="AIzaSyDQIjW5d7bcCFPuwKaBeH_9l_zHjbvmVV4")
model = genai.GenerativeModel('gemini-1.5-flash')


def get_ai_summary(title, abstract):
    # æ„å»ºç²¾å‡†çš„ Prompt
    prompt = f"""
    è¯·ä½œä¸ºAIé¢†åŸŸä¸“å®¶ï¼Œç”¨ä¸­æ–‡åˆ†æè¿™ç¯‡è®ºæ–‡å¹¶è¾“å‡ºï¼š
    1. Summaryï¼ˆä¸€å¥è¯æ¦‚æ‹¬è®ºæ–‡ç›®çš„ï¼‰
    2. Methodsï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
    3. æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼ˆè¯·ç”¨3ä¸ªç®€çŸ­çš„åˆ—è¡¨ç¬¦å·å±•ç¤ºï¼‰

    è®ºæ–‡æ ‡é¢˜: {title}
    æ‘˜è¦: {abstract}
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except:
        return "æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹åŸæ–‡ã€‚"


def fetch_papers():
    # æœç´¢ arXiv æœ€æ–° AI è®ºæ–‡
    search = arxiv.Search(
        query="cat:cs.AI OR cat:cs.LG",
        max_results=5,
        sort_by=arxiv.SortCriterion.SubmittedDate
    )

    papers_data = []
    print("æ­£åœ¨æ¬è¿è®ºæ–‡å¹¶è¯·æ±‚ Gemini æ€»ç»“ï¼Œè¯·ç¨å€™...")

    for result in search.results():
        summary_text = get_ai_summary(result.title, result.summary)
        papers_data.append({
            "title": result.title,
            "link": result.pdf_url,
            "authors": ", ".join(author.name for author in result.authors[:3]),
            "ai_summary": summary_text,  # ğŸ‘ˆ æ£€æŸ¥è¿™é‡Œï¼ä¸€å®šè¦å« ai_summary
            "category": "Artificial Intelligence",  # ğŸ‘ˆ æ£€æŸ¥è¿™é‡Œï¼ä¸€å®šè¦å« category
            "id": result.entry_id.split('/')[-1]  # ğŸ‘ˆ æ£€æŸ¥è¿™é‡Œï¼ä¸€å®šè¦å« id
        })

    # ä¿å­˜ä¸º JSON æ–‡ä»¶ä¾›ç½‘é¡µè¯»å–
    output = {
        "update_time": str(datetime.now().strftime("%Y-%m-%d %H:%M")),
        "papers": papers_data
    }
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=4)
    print("æ•°æ®æ›´æ–°æˆåŠŸï¼ç”Ÿæˆäº† data.json")


if __name__ == "__main__":
    fetch_papers()